{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "from skimage.transform import rotate\n",
    "import scipy.ndimage\n",
    "from spectral import *\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#  load the Indian pines dataset which is the .mat format\n",
    "def loadIndianPinesData():\n",
    "\tdata_path = os.path.join(os.getcwd(), 'data')\n",
    "\tdata = sio.loadmat(os.path.join(data_path, 'Indian_pines.mat'))['indian_pines']\n",
    "\tlabels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "\n",
    "\treturn data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#  split data to Train and Test Set\n",
    "def splitTrainTestSet(X, y, classnum=16, testRatio=0.50):\n",
    "\t# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=testRatio, random_state=345, stratify=y)\n",
    "\tss = StratifiedShuffleSplit(n_splits=classnum, test_size=testRatio, train_size=1 - testRatio, random_state=0)\n",
    "\t# print(classnum)\n",
    "\t# print(testRatio)\n",
    "\tfor train_index, test_index in ss.split(X, y):\n",
    "\t\tprint(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#  over sample\n",
    "def oversampleWeakClasses(X, y):\n",
    "\tuniqueLabels, labelCounts = np.unique(y, return_counts=True)\n",
    "\tmaxCount = np.max(labelCounts)\n",
    "\tlabelInverseRatios = maxCount / labelCounts\n",
    "\t# repeat for every label and concat\n",
    "\tnewX = X[y == uniqueLabels[0], :].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "\tnewY = y[y == uniqueLabels[0]].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "\tfor label, labelInverseRatio in zip(uniqueLabels[1:], labelInverseRatios[1:]):\n",
    "\t\tcX = X[y == label, :].repeat(round(labelInverseRatio), axis=0)\n",
    "\t\tcY = y[y == label].repeat(round(labelInverseRatio), axis=0)\n",
    "\t\tnewX = np.concatenate((newX, cX))\n",
    "\t\tnewY = np.concatenate((newY, cY))\n",
    "\tnp.random.seed(seed=42)\n",
    "\trand_perm = np.random.permutation(newY.shape[0])\n",
    "\tnewX = newX[rand_perm, :, :, :]\n",
    "\tnewY = newY[rand_perm]\n",
    "\treturn newX, newY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#  standartize\n",
    "def standartizeData(X):\n",
    "\tnewX = np.reshape(X, (-1, X.shape[2]))\n",
    "\tscaler = preprocessing.StandardScaler().fit(newX)\n",
    "\tnewX = scaler.transform(newX)\n",
    "\tnewX = np.reshape(newX, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "\treturn newX, scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#  apply PCA preprocessing for data sets\n",
    "def applyPCA(X, numComponents=30):\n",
    "\tnewX = np.reshape(X, (-1, X.shape[2]))\n",
    "\tpca = PCA(n_components=numComponents, whiten=True)\n",
    "\tnewX = pca.fit_transform(newX)\n",
    "\tnewX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n",
    "\treturn newX, pca"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# #  上下左右各补margin个0\n",
    "def padWithZeros(X, margin=2):\n",
    "\tnewX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2 * margin, X.shape[2]))\n",
    "\tx_offset = margin\n",
    "\ty_offset = margin\n",
    "\tnewX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "\treturn newX"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#  create Patches for dataset\n",
    "#  N: batch;\n",
    "#  C: channel\n",
    "#  H: height\n",
    "#  W: width\n",
    "#  Tensorflow的tensor通道顺序：默认是NHWC， 也支持NCHW\n",
    "#  (batch_size, height, width, channels)\n",
    "def createPatches(X, y, windowSize=5, removeZeroLabels=True):\n",
    "\tmargin = int((windowSize - 1) / 2)\n",
    "\tzeroPaddedX = padWithZeros(X, margin=margin)\n",
    "\t# split patches\n",
    "\tpatchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "\tpatchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "\tpatchIndex = 0\n",
    "\tfor r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "\t\tfor c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "\t\t\tpatch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
    "\t\t\tpatchesData[patchIndex, :, :, :] = patch\n",
    "\t\t\tpatchesLabels[patchIndex] = y[r - margin, c - margin]\n",
    "\t\t\tpatchIndex = patchIndex + 1\n",
    "\tif removeZeroLabels:\n",
    "\t\tpatchesData = patchesData[patchesLabels > 0, :, :, :]\n",
    "\t\tpatchesLabels = patchesLabels[patchesLabels > 0]\n",
    "\t\tpatchesLabels -= 1\n",
    "\treturn patchesData, patchesLabels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#  Augment Data\n",
    "def AugmentData(X_train):\n",
    "\tfor i in range(int(X_train.shape[0] / 2)):\n",
    "\t\tpatch = X_train[i, :, :, :]\n",
    "\t\tnum = random.randint(0, 2)\n",
    "\t\tif (num == 0):\n",
    "\t\t\tflipped_patch = np.flipud(patch)\n",
    "\t\tif (num == 1):\n",
    "\t\t\tflipped_patch = np.fliplr(patch)\n",
    "\t\tif (num == 2):\n",
    "\t\t\tno = random.randrange(-180, 180, 30)\n",
    "\t\t\tflipped_patch = scipy.ndimage.interpolation.rotate(patch, no, axes=(1, 0), reshape=False, output=None,\n",
    "\t\t\t                                                   order=3, mode='constant', cval=0.0, prefilter=False)\n",
    "\tpatch2 = flipped_patch\n",
    "\tX_train[i, :, :, :] = patch2\n",
    "\n",
    "\treturn X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# save Preprocessed Data to file\n",
    "def savePreprocessedData(path, X_trainPatches, X_testPatches, y_trainPatches,\n",
    "                         y_testPatches, X_all, y_all, windowSize, wasPCAapplied=False,\n",
    "                         numPCAComponents=0, testRatio=0.25):\n",
    "\t# os.mkdir(os.path.join(os.getcwd(), path))\n",
    "\tdata_path = os.path.join(os.getcwd(), path)\n",
    "\n",
    "\tif wasPCAapplied:\n",
    "\t\twith open(os.path.join(data_path, \"XtrainWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, X_trainPatches)\n",
    "\t\twith open(os.path.join(data_path, \"XtestWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, X_testPatches)\n",
    "\t\twith open(os.path.join(data_path, \"ytrainWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, y_trainPatches)\n",
    "\t\twith open(os.path.join(data_path, \"ytestWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, y_testPatches)\n",
    "\n",
    "\t\twith open(os.path.join(data_path, \"XAllWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, X_all)\n",
    "\t\twith open(os.path.join(data_path, \"yAllWindowSize\") + str(windowSize) +\n",
    "\t\t          \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, y_all)\n",
    "\telse:\n",
    "\t\twith open(os.path.join(data_path, \"preXtrainWindowSize\") + str(windowSize) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, X_trainPatches)\n",
    "\t\twith open(os.path.join(data_path, \"preXtestWindowSize\") + str(windowSize) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, X_testPatches)\n",
    "\t\twith open(os.path.join(data_path, \"preytrainWindowSize\") + str(windowSize) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, y_trainPatches)\n",
    "\t\twith open(os.path.join(data_path, \"preytestWindowSize\") + str(windowSize) +\n",
    "\t\t          \".npy\", 'bw') as outfile:\n",
    "\t\t\tnp.save(outfile, y_testPatches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "# The number of principal components to be retained in the PCA algorithm,\n",
    "# the number of retained features  n\n",
    "numComponents = 30\n",
    "# Patches windows size\n",
    "windowSize = 9\n",
    "# The proportion of Test sets\n",
    "testRatio = 0.75"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/root/autodl-tmp/\")\n",
    "PATH = os.getcwd()\n",
    "print(PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperspectral data shape:  (145, 145, 220)\n",
      "Label shape:  (145, 145)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from file and apply PCA\n",
    "# X, y = loadHSIData()\n",
    "X, y = loadIndianPinesData()\n",
    "print('Hyperspectral data shape: ', X.shape)\n",
    "print('Label shape: ', y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after PCA:  (145, 145, 30)\n",
      "Label shape:  (145, 145)\n"
     ]
    }
   ],
   "source": [
    "X, pca = applyPCA(X, numComponents=numComponents)\n",
    "print('Data shape after PCA: ', X.shape)\n",
    "print('Label shape: ', y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = imshow(classes=y, figsize=(10, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [3942 9919 3072 ... 8888 1881 7201] TEST: [4058 4124 7452 ... 1081  378 2863]\n",
      "TRAIN: [2006 6369 7055 ... 2435 3704 5828] TEST: [6719 3723 7948 ... 8536 5976 1234]\n",
      "TRAIN: [ 6103  3941  3572 ...   987  2340 10088] TEST: [5562 5335 2217 ... 1583 7692 7532]\n",
      "TRAIN: [4474 5113 1676 ... 1537  157 2147] TEST: [7147  425 9994 ...  396 6462 5465]\n",
      "TRAIN: [6835 1337 9810 ... 9073 7814 5228] TEST: [3277 9959 8322 ... 2255 6947 1748]\n",
      "TRAIN: [4747 6028 2937 ... 8800 5591 7823] TEST: [3318 8308 1737 ...   80 1944 7086]\n",
      "TRAIN: [ 510 9944  383 ... 2666 5120 8798] TEST: [3725  855 8258 ... 9332 3788   14]\n",
      "TRAIN: [6378 2035 6491 ... 5914 9514 4076] TEST: [8813  452 9483 ... 9269 4709 1983]\n",
      "TRAIN: [5074 6339 2542 ... 5851  688 1596] TEST: [7855 3934 1364 ... 4701 8910 3707]\n",
      "TRAIN: [7697  436 8812 ... 9791 8115 4687] TEST: [4930 9034 2719 ... 2035 8032 4445]\n",
      "TRAIN: [8352 7131 7054 ... 8195 6377 5827] TEST: [5111 9498 8670 ... 2692 1158 3871]\n",
      "TRAIN: [8340 1544 5570 ... 7620 7633 8527] TEST: [5339 5532 7249 ... 2063 4387 4500]\n",
      "TRAIN: [4205 2859 1933 ... 4770  771 6814] TEST: [1571 3728 1393 ...  493 5223 3875]\n",
      "TRAIN: [8599 6125 5043 ...  712 2032  589] TEST: [3983 6561 1070 ... 3102 5697 4525]\n",
      "TRAIN: [4599  157 7876 ... 4751 4254 2351] TEST: [  72 8879  280 ... 7777 6819 7294]\n",
      "TRAIN: [6550 5783  183 ...  878 5586 9014] TEST: [8500 6028 1533 ... 3067 7770 8312]\n"
     ]
    }
   ],
   "source": [
    "XPatches, yPatches = createPatches(X, y, windowSize=windowSize)\n",
    "X_train, X_test, y_train, y_test = splitTrainTestSet(XPatches, yPatches, y.max() - y.min(), testRatio)\n",
    "X_all = np.append(X_train, X_test, axis=0)\n",
    "y_all = np.append(y_train, y_test, axis=0)\n",
    "X_train, y_train = oversampleWeakClasses(X_train, y_train)\n",
    "# X_all, y_all = oversampleWeakClasses(X_all, y_all)\n",
    "X_train = AugmentData(X_train)\n",
    "# X_all = AugmentData(X_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (9901, 9, 9, 30)\n",
      "y_train shape:  (9901,)\n",
      "X_test shape:  (7687, 9, 9, 30)\n",
      "y_test shape:  (7687,)\n"
     ]
    }
   ],
   "source": [
    "# print(XPatches.shape)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "# print(yPatches.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "#  (batch_size, height, width, channels)\n",
    "#  batch_size当成总的训练样本数，height和width图片的长宽，channels为图片的通道数，类似于彩色图片的rgb三通道\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# save Preprocessed Data to file\n",
    "savePreprocessedData('predata', X_train, X_test, y_train, y_test,\n",
    "                     X_all, y_all, windowSize=windowSize,\n",
    "                     wasPCAapplied=True, numPCAComponents=numComponents,\n",
    "                     testRatio=testRatio)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:32:11.186899: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "# K.set_image_dim_ordering('th')\n",
    "# K.set_image_data_format('channels_first')  # 这个data_format参数是这样影响input_shape工作的如果不填写，默认是channels_last，否则可以填写channels_first。前者的会把input_shape这个三元组给识别成(batch_size, height, width, channels)，后者则会识别成(batch_size, channels, height, width)\n",
    "from keras.utils import np_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "# The number of principal components to be retained in the PCA algorithm,\n",
    "# the number of retained features  n\n",
    "numPCAcomponents = 30\n",
    "# Patches windows size\n",
    "windowSize = 9\n",
    "# The proportion of Test sets\n",
    "testRatio = 0.75"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_train = np.load(\"./predata/XtrainWindowSize\"\n",
    "                  + str(windowSize) + \"PCA\" + str(numPCAcomponents) +\n",
    "                  \"testRatio\" + str(testRatio) + \".npy\")\n",
    "y_train = np.load(\"./predata/ytrainWindowSize\"\n",
    "                  + str(windowSize) + \"PCA\" + str(numPCAcomponents) +\n",
    "                  \"testRatio\" + str(testRatio) + \".npy\")\n",
    "X_test = np.load(\"./predata/XtestWindowSize\"\n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) +\n",
    "                 \"testRatio\" + str(testRatio) + \".npy\")\n",
    "y_test = np.load(\"./predata/ytestWindowSize\"\n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) +\n",
    "                 \"testRatio\" + str(testRatio) + \".npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (9, 9, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],\n",
    "                               X_train.shape[2], X_train.shape[3]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],\n",
    "                             X_test.shape[2], X_test.shape[3]))\n",
    "\n",
    "# convert class labels to on-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = X_train[0].shape  # 也可再Conv2d中设置input_shape=input_shape[1:]\n",
    "print('input shape: ', input_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (9901, 9, 9, 30)\n",
      "y_train shape:  (9901, 16)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "RDB_num = 4\n",
    "filters = 64\n",
    "one_conv_num = 3\n",
    "growth_rate = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class one_conv(layers.Layer):\n",
    "\tdef __init__(self, out_channel, **kwargs):\n",
    "\t\tsuper(one_conv, self).__init__(**kwargs)\n",
    "\t\tself.out_channel = out_channel\n",
    "\t\tself.conv = layers.Conv2D(out_channel, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)\n",
    "\t\tself.relu = layers.ReLU()\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\tx = self.conv(inputs)\n",
    "\t\tx = self.relu(x)\n",
    "\t\tx = layers.concatenate([inputs, x], 3)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef get_config(self):\n",
    "\t\tconfig = super().get_config().copy()\n",
    "\t\tconfig.update({\n",
    "\t\t\t'out_channel': self.out_channel\n",
    "\t\t})\n",
    "\t\treturn config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class rdb(layers.Layer):\n",
    "\tdef __init__(self, filters, one_conv_num, growth_rate, **kwargs):\n",
    "\t\tsuper(rdb, self).__init__(**kwargs)\n",
    "\t\tself.filters = filters  # 除残差密集模块中的卷积层外的层滤波器个数\n",
    "\t\tself.one_conv_num = one_conv_num  # the number of RDB 模块个数\n",
    "\t\tself.growth_rate = growth_rate  # 增长比率，残差密集模块3x3核的输出个数\n",
    "\t\tconvs = []\n",
    "\t\tfor i in range(0, one_conv_num):\n",
    "\t\t\tconvs.append(one_conv(growth_rate))\n",
    "\t\tself.conv = Sequential(convs)\n",
    "\t\t#local_feature_fusion\n",
    "\t\tself.LFF = layers.Conv2D(filters, kernel_size=1, strides=1, padding=\"same\", use_bias=False)  # 特征融合层\n",
    "\t\tself.add = layers.Add()\n",
    "\t\tself.relu = layers.ReLU()\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\tx = self.conv(inputs)\n",
    "\t\tx = self.relu(x)\n",
    "\t\tlff = self.LFF(x)\n",
    "\t\tlff = self.relu(lff)\n",
    "\t\t#local residual learning\n",
    "\t\tx = self.add([inputs, lff])\n",
    "\t\treturn x\n",
    "\n",
    "\tdef get_config(self):\n",
    "\t\tconfig = super().get_config().copy()\n",
    "\t\tconfig.update({\n",
    "\t\t\t'filters': self.filters,\n",
    "\t\t\t'one_conv_num': self.one_conv_num,\n",
    "\t\t\t'growth_rate': self.growth_rate\n",
    "\t\t})\n",
    "\t\treturn config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class RDB(layers.Layer):\n",
    "\tdef __init__(self, filters, one_conv_num, growth_rate, **kwargs):\n",
    "\t\tsuper(RDB, self).__init__(**kwargs)\n",
    "\t\tself.filters = filters\n",
    "\t\tself.one_conv_num = one_conv_num\n",
    "\t\tself.growth_rate = growth_rate\n",
    "\t\tself.conv = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "\t\tself.rdbs = rdb(filters, one_conv_num, growth_rate)\n",
    "\t\tself.MaxPool2D = layers.MaxPool2D(pool_size=3, strides=1, padding='same')\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\tx = self.conv(inputs)\n",
    "\t\tx = self.rdbs(x)\n",
    "\t\tx = self.MaxPool2D(x)\n",
    "\t\tx = layers.concatenate([inputs, x], 3)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef get_config(self):\n",
    "\t\tconfig = super().get_config().copy()\n",
    "\t\tconfig.update({\n",
    "\t\t\t'filters': self.filters,\n",
    "\t\t\t'one_conv_num': self.one_conv_num,\n",
    "\t\t\t'growth_rate': self.growth_rate\n",
    "\t\t})\n",
    "\t\treturn config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def _make_layer(block, RDB_num, filters, one_conv_num, growth_rate):\n",
    "\tlayers_list = []\n",
    "\tfor i in range(RDB_num):\n",
    "\t\tlayers_list.append(block(filters, one_conv_num, growth_rate))\n",
    "\treturn Sequential(layers_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# def _make_layer(block, RDB_num, filters, one_conv_num, growth_rate):\n",
    "#     layers_list = []\n",
    "#     for i in range(RDB_num):\n",
    "#         layers_list.append(block(filters,one_conv_num,growth_rate))\n",
    "#         layers_list.append(layers.MaxPooling2D(pool_size=1,padding=\"SAME\"))\n",
    "#     return Sequential(layers_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def _rdn(RDB_num, filters, one_conv_num, growth_rate, im_width=17, im_height=17, numclasses=16):\n",
    "\tinput_image = layers.Input(shape=(im_height, im_width, 30), dtype=\"float32\")\n",
    "\t# shallow feature extraction\n",
    "\tx = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)(input_image)\n",
    "\tx = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)(x)\n",
    "\t# x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "\tx = layers.ReLU()(x)\n",
    "\tx = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\")(x)\n",
    "\tidentity = x\n",
    "\n",
    "\t#RDB for paper we have D RDB block\n",
    "\tx = _make_layer(RDB, RDB_num, filters, one_conv_num, growth_rate)(x)\n",
    "\n",
    "\t# dense feature fusion(DFF)功能：全局特征学习\n",
    "\tx = layers.Conv2D(filters=64, kernel_size=1, strides=1, padding=\"SAME\", use_bias=False)(x)  # 全局特征融合\n",
    "\tx = layers.ReLU()(x)\n",
    "\tx = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)(x)  # 全局特征融合\n",
    "\tx = layers.ReLU()(x)\n",
    "\tx = layers.add([x, identity])  #全局残差学习\n",
    "\n",
    "\tx = layers.GlobalMaxPool2D()(x)  # pool + flatten\n",
    "\tx = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "\tx = layers.Dropout(rate=0.4)(x)\n",
    "\tx = layers.Dense(numclasses)(x)\n",
    "\tpredict = layers.Softmax()(x)\n",
    "\n",
    "\tmodel = Model(inputs=input_image, outputs=predict)\n",
    "\n",
    "\treturn model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def rdn(RDB_num=2, filters=64, one_conv_num=3, growth_rate=32, im_width=17, im_height=17, num_classes=16):\n",
    "\treturn _rdn(RDB_num, filters, one_conv_num, growth_rate, im_width, im_height, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:32:12.732123: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-02 12:32:12.837098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-05-02 12:32:12.837140: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-02 12:32:12.840152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-02 12:32:12.840191: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-02 12:32:12.841022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-02 12:32:12.841245: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-02 12:32:12.842116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-02 12:32:12.842641: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-02 12:32:12.842772: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-02 12:32:12.843630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-02 12:32:12.844090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 12:32:12.850360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-05-02 12:32:12.851148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-02 12:32:12.851184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-02 12:32:13.365025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-02 12:32:13.365055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-02 12:32:13.365063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-02 12:32:13.367075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22358 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:25:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "model = rdn(RDB_num, filters, one_conv_num, growth_rate, im_width=9, im_height=9, num_classes=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# model = load_model('./model/HSI_model_epochs100.h5', custom_objects={'one_conv': one_conv, 'rdb': rdb, 'RDB': RDB})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 9, 9, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 9, 9, 64)     17280       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 64)     36864       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 9, 9, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 5, 5, 64)     0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 5, 5, 320)    1318912     max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 5, 5, 64)     20480       sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 5, 5, 64)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 5, 5, 64)     36864       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 5, 5, 64)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 5, 5, 64)     0           re_lu_18[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 64)           0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           1040        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 16)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,431,696\n",
      "Trainable params: 1,431,568\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Define optimization and train method\n",
    "# monitor：监测的值，可以是accuracy，val_loss,val_accuracy\n",
    "# factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少\n",
    "# patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发\n",
    "# mode：‘auto’，‘min’，‘max’之一 默认‘auto’就行\n",
    "# epsilon：阈值，用来确定是否进入检测值的“平原区”\n",
    "# cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作\n",
    "# min_lr：学习率最小值，能缩小到的下限\n",
    "# verbose(bool)-如果为True，则为每次更新向stdout输出一条消息。默认值：False。\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9, patience=5, min_lr=0.000001, verbose=1)\n",
    "\n",
    "# 该回调函数将在每个epoch后保存模型到filepath\n",
    "# filepath，保存模型的路径，里面的占位符将会被epoch值和传入on_epoch_end的logs关键字所填入\n",
    "# monitor：需要监视的值，通常为：val_accuracy 或 val_loss 或 accuracy 或 loss\n",
    "# verbose：信息展示模式，0或1。为1表示输出epoch模型保存信息，默认为0表示不输出该信息，信息形如：\n",
    "# Epoch 00001: val_acc improved from -inf to 0.49240, saving model to /xxx/checkpoint/model_001-0.3902.h5\n",
    "# save_best_only：当设置为True时，将只保存在验证集上性能最好的模型\n",
    "# mode：‘auto’，‘min’，‘max’之一，在save_best_only=True时决定性能最佳模型的评判准则，例如，当监测值为val_acc时，模式应为max，当检测值为val_loss时，模式应为min。在auto模式下，评价准则由被监测值的名字自动推断。\n",
    "# save_weights_only：若设置为True，则只保存模型权重，否则将保存整个模型（包括模型结构，配置信息等）\n",
    "# period：CheckPoint之间的间隔的epoch数\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"checkpoint.hdf5\", verbose=1, save_best_only=False)\n",
    "sgd = SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:32:14.504422: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-02 12:32:14.505536: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2800110000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 12:32:15.730811: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-02 12:32:16.355044: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2022-05-02 12:32:17.176679: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-02 12:32:17.722581: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-02 12:32:17.781579: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 11s 23ms/step - loss: 0.5709 - accuracy: 0.8399 - val_loss: 0.2430 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: saving model to checkpoint.hdf5\n",
      "Epoch 2/50\n",
      "  9/310 [..............................] - ETA: 4s - loss: 0.1601 - accuracy: 0.9722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 7s 21ms/step - loss: 0.1103 - accuracy: 0.9797 - val_loss: 0.1200 - val_accuracy: 0.9679\n",
      "\n",
      "Epoch 00002: saving model to checkpoint.hdf5\n",
      "Epoch 3/50\n",
      "310/310 [==============================] - 7s 21ms/step - loss: 0.0512 - accuracy: 0.9935 - val_loss: 0.0735 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00003: saving model to checkpoint.hdf5\n",
      "Epoch 4/50\n",
      "310/310 [==============================] - 7s 21ms/step - loss: 0.0275 - accuracy: 0.9987 - val_loss: 0.0580 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00004: saving model to checkpoint.hdf5\n",
      "Epoch 5/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 0.0552 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00005: saving model to checkpoint.hdf5\n",
      "Epoch 6/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0153 - accuracy: 0.9998 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00006: saving model to checkpoint.hdf5\n",
      "Epoch 7/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00007: saving model to checkpoint.hdf5\n",
      "Epoch 8/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00008: saving model to checkpoint.hdf5\n",
      "Epoch 9/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00009: saving model to checkpoint.hdf5\n",
      "Epoch 10/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00010: saving model to checkpoint.hdf5\n",
      "Epoch 11/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00011: saving model to checkpoint.hdf5\n",
      "Epoch 12/50\n",
      "310/310 [==============================] - 6s 19ms/step - loss: 0.0070 - accuracy: 0.9999 - val_loss: 0.0360 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00012: saving model to checkpoint.hdf5\n",
      "Epoch 13/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0068 - accuracy: 0.9999 - val_loss: 0.0357 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00013: saving model to checkpoint.hdf5\n",
      "Epoch 14/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00014: saving model to checkpoint.hdf5\n",
      "Epoch 15/50\n",
      "310/310 [==============================] - 6s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00015: saving model to checkpoint.hdf5\n",
      "Epoch 16/50\n",
      "310/310 [==============================] - 6s 20ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00016: saving model to checkpoint.hdf5\n",
      "Epoch 17/50\n",
      "178/310 [================>.............] - ETA: 2s - loss: 0.0051 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_129515/3859550053.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Start to train model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m history = model.fit(X_train, y_train,\n\u001B[0m\u001B[1;32m      3\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Start to train model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[reduce_lr, checkpointer],\n",
    "                    shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the model with h5py\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('./model/HSI_model_epochs100.h5')\n",
    "print('Model saved.')\n",
    "# model.save('model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# using plot_model module to save the model figure\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='./model/model.png', show_shapes=True, show_layer_names=True, rankdir='TB',\n",
    "           expand_nested=True)\n",
    "# print(history.history.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "model_img = plt.imread('./model/model.png')\n",
    "plt.imshow(model_img)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# os.mkdir(os.path.join(os.getcwd(), 'result'))\n",
    "plt.savefig(\"./result/model_accuracy_100.svg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(\"./result/model_loss_100.svg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import itertools\n",
    "import spectral\n",
    "from operator import truediv\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the neccesary functions for later use\n",
    "# load the Indian pines dataset which is the .mat format\n",
    "def loadIndianPinesData():\n",
    "\tdata_path = os.path.join(os.getcwd(), 'data')\n",
    "\tdata = sio.loadmat(os.path.join(data_path, 'Indian_pines.mat'))['indian_pines']\n",
    "\tlabels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "\n",
    "\treturn data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "\t, 'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',\n",
    "\t            'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "\t            'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "\t            'Stone-Steel-Towers']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "\tcounter = confusion_matrix.shape[0]\n",
    "\tlist_diag = np.diag(confusion_matrix)\n",
    "\tlist_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "\teach_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "\taverage_acc = np.mean(each_acc)\n",
    "\treturn each_acc, average_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reports(X_test, y_test):\n",
    "\tY_pred = model.predict(X_test)\n",
    "\ty_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "\tclassification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names, digits=4)\n",
    "\tconfusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "\tscore = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "\toa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "\teach_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "\tkappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "\tTest_Loss = score[0] * 100\n",
    "\tTest_accuracy = score[1] * 100\n",
    "\toa = oa * 100\n",
    "\teach_acc = each_acc * 100\n",
    "\taa = aa * 100\n",
    "\tkappa = kappa * 100\n",
    "\treturn classification, confusion, Test_Loss, Test_accuracy, oa, each_acc, aa, kappa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Patch(data, height_index, width_index):\n",
    "\t#transpose_array = data.transpose((2,0,1))\n",
    "\t#print transpose_array.shape\n",
    "\tmargin = int((PATCH_SIZE - 1) / 2)\n",
    "\tzeroPaddedX = padWithZeros(data, margin=margin)\n",
    "\theight_slice = slice(height_index, height_index + PATCH_SIZE)\n",
    "\twidth_slice = slice(width_index, width_index + PATCH_SIZE)\n",
    "\tpatch = zeroPaddedX[height_slice, width_slice, :]\n",
    "\n",
    "\treturn patch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show current path\n",
    "PATH = os.getcwd()\n",
    "print(PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read PreprocessedData from file\n",
    "\n",
    "X_test = np.load(\"./predata/XtestWindowSize\"\n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
    "y_test = np.load(\"./predata/ytestWindowSize\"\n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
    "\n",
    "# X_test = np.load(\"./predata/XAllWindowSize\"\n",
    "#                  + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
    "# y_test = np.load(\"./predata/yAllWindowSize\"\n",
    "#                  + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3]))\n",
    "y_test = np_utils.to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the model architecture and weights\n",
    "model = load_model('./model/HSI_model_epochs100.h5', custom_objects={'one_conv': one_conv, 'rdb': rdb, 'RDB': RDB})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate result, loss, accuray and confusion matrix\n",
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(X_test, y_test)\n",
    "classification = str(classification)\n",
    "confusion_str = str(confusion)\n",
    "\n",
    "# show result and save to file\n",
    "print('Test loss {} (%)'.format(Test_loss))\n",
    "print('Test accuracy {} (%)'.format(Test_accuracy))\n",
    "print('Kappa accuracy {} (%)'.format(kappa))\n",
    "print('Overall accuracy {} (%)'.format(oa))\n",
    "print('Average accuracy {} (%)'.format(aa))\n",
    "print(\"classification result: \")\n",
    "print('{}'.format(classification))\n",
    "print(\"confusion matrix: \")\n",
    "print('{}'.format(confusion_str))\n",
    "file_name = './result/report' + \"WindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(\n",
    "\ttestRatio) + \".txt\"\n",
    "with open(file_name, 'w') as x_file:\n",
    "\tx_file.write('Test loss {} (%)'.format(Test_loss))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write('Test accuracy {} (%)'.format(Test_accuracy))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write('Kappa accuracy {} (%)'.format(kappa))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write('Overall accuracy {} (%)'.format(oa))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write('Average accuracy {} (%)'.format(aa))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write(\" classification result: \\n\")\n",
    "\tx_file.write('{}'.format(classification))\n",
    "\tx_file.write('\\n')\n",
    "\tx_file.write(\" confusion matrix: \\n\")\n",
    "\tx_file.write('{}'.format(confusion_str))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.get_cmap(\"Blues\")):\n",
    "\t\"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\tNormalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\tif normalize:\n",
    "\t\tcm = Normalized\n",
    "\t\tprint(\"Normalized confusion matrix\")\n",
    "\telse:\n",
    "\t\tprint('Confusion matrix, without normalization')\n",
    "\n",
    "\tprint(cm)\n",
    "\n",
    "\tplt.imshow(Normalized, interpolation='nearest', cmap=cmap)\n",
    "\tplt.colorbar()\n",
    "\tplt.title(title)\n",
    "\ttick_marks = np.arange(len(classes))\n",
    "\tplt.xticks(tick_marks, classes, rotation=90)\n",
    "\tplt.yticks(tick_marks, classes)\n",
    "\n",
    "\tfmt = '.4f' if normalize else 'd'\n",
    "\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\t\tthresh = cm[i].max() / 2.\n",
    "\t\tplt.text(j, i, format(cm[i, j], fmt),\n",
    "\t\t         horizontalalignment=\"center\",\n",
    "\t\t         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.ylabel('True label')\n",
    "\tplt.xlabel('Predicted label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plot_confusion_matrix(confusion, classes=target_names, normalize=False, title='Confusion matrix, without normalization')\n",
    "plt.savefig(\"./result/confusion_matrix_without_normalization.svg\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 15))\n",
    "plot_confusion_matrix(confusion, classes=target_names, normalize=True, title='Normalized confusion matrix')\n",
    "plt.savefig(\"./result/confusion_matrix_with_normalization.svg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # load the original image\n",
    "X, y = loadIndianPinesData()\n",
    "# # X, y = loadHSIData()\n",
    "X, pca = applyPCA(X, numComponents=numPCAcomponents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = 9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('X_shape: ', X.shape)\n",
    "print('y_shape: ', y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height, width))\n",
    "for i in tqdm(range(height)):\n",
    "\tfor j in range(width):\n",
    "\t\ttarget = y[i][j]\n",
    "\t\tif target == 0:\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\timage_patch = Patch(X, i, j)\n",
    "\t\t\t# print (image_patch.shape)\n",
    "\t\t\tX_test_image = image_patch.reshape(1, image_patch.shape[0], image_patch.shape[1],\n",
    "\t\t\t                                   image_patch.shape[2]).astype('float32')\n",
    "\t\t\t# print(X_test_image.shape)\n",
    "\t\t\t# prediction = np.argmax(model.predict(X_test_image),axis=1)\n",
    "\t\t\tprediction = model.predict(X_test_image)\n",
    "\t\t\tprediction = np.argmax(prediction, axis=1)\n",
    "\t\t\t# (model.predict_classes(X_test_image))\n",
    "\t\t\toutputs[i][j] = prediction + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes=y, figsize=(10, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_image = spectral.imshow(classes=outputs.astype(int), figsize=(10, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}